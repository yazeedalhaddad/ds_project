# -*- coding: utf-8 -*-
"""snw_depth_calculation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10jvqRCUscxDlXLR03EXltLxWzt1XA_Zm
"""

import pandas as pd

# Direct file reading approach
try:
    # Read the CSV file with proper settings
    df = pd.read_csv('/content/smhi-opendata_4_97100_202201_202506.csv',
                    sep=';',
                    encoding='utf-8-sig',  # Handle BOM
                    skiprows=7,  # Skip metadata rows
                    names=['Datum', 'Tid (UTC)', 'Vindriktning', 'Kvalitet_VR', 'Vindhastighet', 'Kvalitet_VH', 'Empty1', 'Tidsutsnitt'])

    # Clean the data
    df = df.drop(['Empty1', 'Tidsutsnitt'], axis=1)

    # Create timestamp and convert numeric columns
    df['Date'] = pd.to_date(df['Datum'] + ' ' + df['Tid (UTC)'])
    df['hod'] =
    df['Vindriktning'] = pd.to_numeric(df['Vindriktning'], errors='coerce')
    df['Vindhastighet'] = pd.to_numeric(df['Vindhastighet'], errors='coerce')

    # Final column selection and ordering
    df_final = df[['Timestamp', 'Vindriktning', 'Kvalitet_VR', 'Vindhastighet', 'Kvalitet_VH']]

    # Save the processed data
    output_file = 'processed_wind_data_clean.csv'
    df_final.to_csv(output_file, index=False, encoding='utf-8')

    print("Data processed successfully!")
    print(f"Output file: {output_file}")
    print(f"Data shape: {df_final.shape}")
    print("\nFirst few rows:")
    print(df_final.head())

except Exception as e:
    print(f"Error processing file: {e}")

import pandas as pd

def process_smhi_data_with_hour(file_path):
    """
    Process SMHI wind data with separate date and hour columns
    Date format: YYYY-MM-DD
    Hour column name: hod (showing only hour value)
    """

    try:
        # Read the CSV file with proper settings
        df = pd.read_csv('/content/smhi-opendata_4_97100_202201_202506.csv',
                        sep=';',
                        encoding='utf-8-sig',  # Handle BOM
                        skiprows=7,  # Skip metadata rows
                        names=['Datum', 'Tid (UTC)', 'Vindriktning', 'Kvalitet_VR', 'Vindhastighet', 'Kvalitet_VH', 'Empty1', 'Tidsutsnitt'])

        # Clean the data
        df = df.drop(['Empty1', 'Tidsutsnitt'], axis=1)

        # Convert to proper datetime with dayfirst=True for DD/MM/YYYY format
        # Specify the format to avoid parsing issues
        df['Timestamp'] = pd.to_datetime(df['Datum'] + ' ' + df['Tid (UTC)'], format='%Y-%m-%d %H:%M:%S')

        # Create separate date and hour columns
        df['Date'] = df['Timestamp'].dt.strftime('%Y-%m-%d')  # YYYY-MM-DD format
        df['hod'] = df['Timestamp'].dt.hour  # Only hour value (0-23)

        # Convert numeric columns
        df['Vindriktning'] = pd.to_numeric(df['Vindriktning'], errors='coerce')
        df['Vindhastighet'] = pd.to_numeric(df['Vindhastighet'], errors='coerce')

        # Final column selection and ordering
        df_final = df[['Date', 'hod', 'Vindriktning', 'Kvalitet_VR', 'Vindhastighet', 'Kvalitet_VH']]

        return df_final

    except Exception as e:
        print(f"Error processing file: {e}")
        return None

# Process the file
file_path = 'smhi-opendata_4_97100_202201_202506.csv'
df_processed = process_smhi_data_with_hour(file_path)

if df_processed is not None:
    # Display information about the processed data
    print("Data processed successfully!")
    print(f"Shape: {df_processed.shape}")
    print(f"Columns: {df_processed.columns.tolist()}")
    print(f"Date range: {df_processed['Date'].min()} to {df_processed['Date'].max()}")
    print(f"Hour range: {df_processed['hod'].min()} to {df_processed['hod'].max()}")

    print("\nFirst 10 rows:")
    print(df_processed.head(10))

    # Save to CSV file
    output_filename = 'wind_data_with_hour.csv'
    df_processed.to_csv(output_filename, index=False, encoding='utf-8')
    print(f"\nFile saved as: {output_filename}")

else:
    print("Failed to process the data.")

import pandas as pd

# Replace with your actual file name
input_file = "/content/drive/MyDrive/Dataset for Introduction to Data Science/smhi-opendata_1_97100_202001_202506-Pre.csv"
output_file = "/content/drive/MyDrive/Dataset for Introduction to Data Science/temperature_split_data.csv"

# Read the semicolon-separated data
df = pd.read_csv(input_file, sep=";", header=None, names=["Date", "Time", "Temperature", "Quality"])

# Save to Excel
df.to_csv(output_file, index=False)

print("‚úÖ Data successfully split and saved to", output_file)

import pandas as pd

# ==== CONFIGURATION ====
temperature_file = "/content/drive/MyDrive/Dataset for Introduction to Data Science/temp.csv"
precipitation_file = "/content/drive/MyDrive/Dataset for Introduction to Data Science/Percipitation.csv"
output_file = "/content/drive/MyDrive/Dataset for Introduction to Data Science/snow_depth_output.xlsx"

date_col = "Date"
time_col = "Time"
temperature_col = "Temperature"
precipitation_col = "Precipitation"

# === 1. READ THE FILES AND CHECK DATA ===
print("üìä Reading files...")
temp_df = pd.read_csv(temperature_file)
prec_df = pd.read_csv(precipitation_file)

print(f"Temperature data shape: {temp_df.shape}")
print(f"Precipitation data shape: {prec_df.shape}")
print(f"Temperature columns: {temp_df.columns.tolist()}")
print(f"Precipitation columns: {prec_df.columns.tolist()}")

# Display first few rows to verify structure
print("\nTemperature data sample:")
print(temp_df.head())
print("\nPrecipitation data sample:")
print(prec_df.head())

# === 2. CHECK FOR MATCHING TIMESTAMPS ===
# Create datetime columns for merging
temp_df['datetime'] = pd.to_datetime(temp_df[date_col] + ' ' + temp_df[time_col])
prec_df['datetime'] = pd.to_datetime(prec_df[date_col] + ' ' + prec_df[time_col])

print(f"\nTemperature date range: {temp_df['datetime'].min()} to {temp_df['datetime'].max()}")
print(f"Precipitation date range: {prec_df['datetime'].min()} to {prec_df['datetime'].max()}")

# === 3. MERGE WITH DIFFERENT STRATEGIES ===
# Try outer merge first to see all data
df_outer = pd.merge(temp_df, prec_df, on=[date_col, time_col], how="outer")
print(f"\nOuter merge shape: {df_outer.shape}")

# Try inner merge (only matching timestamps)
df_inner = pd.merge(temp_df, prec_df, on=[date_col, time_col], how="inner")
print(f"Inner merge shape: {df_inner.shape}")

if df_inner.empty:
    print("‚ùå No matching timestamps found! Trying alternative approach...")

    # Alternative: Merge on datetime column
    df = pd.merge(temp_df, prec_df, on='datetime', how='inner')
    print(f"Merge on datetime shape: {df.shape}")

    if df.empty:
        print("‚ùå Still no data. Let's try forward/backward filling...")

        # Set datetime as index and resample
        temp_df_indexed = temp_df.set_index('datetime')
        prec_df_indexed = prec_df.set_index('datetime')

        # Resample to hourly and forward fill
        temp_resampled = temp_df_indexed.resample('H').ffill()
        prec_resampled = prec_df_indexed.resample('H').ffill()

        # Merge the resampled data
        df = pd.merge(temp_resampled.reset_index(),
                     prec_resampled.reset_index(),
                     on='datetime', how='inner')
        print(f"Resampled merge shape: {df.shape}")

        # Extract date and time from datetime
        df[date_col] = df['datetime'].dt.date
        df[time_col] = df['datetime'].dt.time
else:
    df = df_inner

# === 4. CHECK IF WE HAVE DATA ===
if df.empty:
    print("‚ùå ERROR: No data after merging. Please check your input files.")
    print("Make sure both files have overlapping date ranges and matching time formats.")
else:
    print(f"‚úÖ Successfully merged data. Final shape: {df.shape}")

    # Sort by datetime
    df = df.sort_values(by='datetime').reset_index(drop=True)

    # === 5. SNOW DEPTH CALCULATION ===
    print("‚ùÑÔ∏è Calculating snow depth...")
    snow_depth = 0
    snow_depth_list = []

    for _, row in df.iterrows():
        temp = row[temperature_col]
        precip = row[precipitation_col]

        # Handle missing values
        if pd.isna(temp) or pd.isna(precip):
            snow_depth_list.append(snow_depth)
            continue

        # Snowfall calculation
        if temp <= 0:
            slr = 10 + (0 - temp)  # Snow-to-liquid ratio
            new_snow = precip * slr / 10
        else:
            new_snow = 0

        # Melt calculation
        if temp > 0:
            melt = temp * 1.0  # Melt rate per ¬∞C
        else:
            melt = 0

        # Update snow depth
        snow_depth = max(snow_depth + new_snow - melt, 0)
        snow_depth_list.append(snow_depth)

    # Add SnowDepth column
    df["SnowDepth"] = snow_depth_list

    # === 6. SAVE FINAL OUTPUT ===
    output_cols = [date_col, time_col, temperature_col, "SnowDepth"]

    # Make sure all required columns exist
    available_cols = [col for col in output_cols if col in df.columns]

    df[available_cols].to_excel(output_file, index=False)
    print(f"‚úÖ Final Snow Depth file saved successfully: {output_file}")
    print(f"Output shape: {df[available_cols].shape}")
    print("\nFirst few rows of output:")
    print(df[available_cols].head(10))

import pandas as pd

# ==== CONFIGURATION ====
temperature_file = "/content/drive/MyDrive/Dataset for Introduction to Data Science/temp.csv"
precipitation_file = "/content/drive/MyDrive/Dataset for Introduction to Data Science/Percipitation.csv"
output_file = "/content/drive/MyDrive/Dataset for Introduction to Data Science/snow_depth_output.xlsx"

date_col = "Date"
time_col = "Time"
temperature_col = "Temperature"
precipitation_col = "Precipitation"

# === 1. READ THE FILES AND CHECK DATA ===
print("üìä Reading files...")
temp_df = pd.read_csv(temperature_file)
prec_df = pd.read_csv(precipitation_file)

print(f"Temperature data shape: {temp_df.shape}")
print(f"Precipitation data shape: {prec_df.shape}")
print(f"Temperature columns: {temp_df.columns.tolist()}")
print(f"Precipitation columns: {prec_df.columns.tolist()}")

# Display first few rows to verify structure
print("\nTemperature data sample:")
print(temp_df.head())
print("\nPrecipitation data sample:")
print(prec_df.head())

# === 2. CHECK FOR MATCHING TIMESTAMPS ===
# Create datetime columns for merging
temp_df['datetime'] = pd.to_datetime(temp_df[date_col] + ' ' + temp_df[time_col])
prec_df['datetime'] = pd.to_datetime(prec_df[date_col] + ' ' + prec_df[time_col])

print(f"\nTemperature date range: {temp_df['datetime'].min()} to {temp_df['datetime'].max()}")
print(f"Precipitation date range: {prec_df['datetime'].min()} to {prec_df['datetime'].max()}")

# === 3. MERGE WITH DIFFERENT STRATEGIES ===
# Try outer merge first to see all data
df_outer = pd.merge(temp_df, prec_df, on=[date_col, time_col], how="outer")
print(f"\nOuter merge shape: {df_outer.shape}")

# Try inner merge (only matching timestamps)
df_inner = pd.merge(temp_df, prec_df, on=[date_col, time_col], how="inner")
print(f"Inner merge shape: {df_inner.shape}")

if df_inner.empty:
    print("‚ùå No matching timestamps found! Trying alternative approach...")

    # Alternative: Merge on datetime column
    df = pd.merge(temp_df, prec_df, on='datetime', how='inner')
    print(f"Merge on datetime shape: {df.shape}")

    if df.empty:
        print("‚ùå Still no data. Let's try forward/backward filling...")

        # Set datetime as index and resample
        temp_df_indexed = temp_df.set_index('datetime')
        prec_df_indexed = prec_df.set_index('datetime')

        # Resample to hourly and forward fill
        temp_resampled = temp_df_indexed.resample('H').ffill()
        prec_resampled = prec_df_indexed.resample('H').ffill()

        # Merge the resampled data
        df = pd.merge(temp_resampled.reset_index(),
                     prec_resampled.reset_index(),
                     on='datetime', how='inner')
        print(f"Resampled merge shape: {df.shape}")

        # Extract date and time from datetime
        df[date_col] = df['datetime'].dt.date
        df[time_col] = df['datetime'].dt.time
else:
    df = df_inner

# === 4. CHECK IF WE HAVE DATA ===
if df.empty:
    print("‚ùå ERROR: No data after merging. Please check your input files.")
    print("Make sure both files have overlapping date ranges and matching time formats.")
else:
    print(f"‚úÖ Successfully merged data. Final shape: {df.shape}")

    # Sort by datetime
    df = df.sort_values(by='datetime').reset_index(drop=True)

    # === 5. SNOW DEPTH CALCULATION ===
    print("‚ùÑÔ∏è Calculating snow depth...")
    snow_depth = 0
    snow_depth_list = []

    for _, row in df.iterrows():
        temp = row[temperature_col]
        precip = row[precipitation_col]

        # Handle missing values
        if pd.isna(temp) or pd.isna(precip):
            snow_depth_list.append(snow_depth)
            continue

        # Snowfall calculation
        if temp <= 0:
            slr = 10 + (0 - temp)  # Snow-to-liquid ratio
            new_snow = precip * slr / 10
        else:
            new_snow = 0

        # Melt calculation
        if temp > 0:
            melt = temp * 1.0  # Melt rate per ¬∞C
        else:
            melt = 0

        # Update snow depth
        snow_depth = max(snow_depth + new_snow - melt, 0)
        snow_depth_list.append(snow_depth)

    # Add SnowDepth column
    df["SnowDepth"] = snow_depth_list

    # === 6. SAVE FINAL OUTPUT ===
    # Include all important columns in output
    output_cols = [date_col, time_col, temperature_col, precipitation_col, "SnowDepth"]

    # Make sure all required columns exist
    available_cols = [col for col in output_cols if col in df.columns]

    print(f"üìÅ Saving output with columns: {available_cols}")

    # Save to Excel
    df[available_cols].to_excel(output_file, index=False)

    print(f"‚úÖ Final Snow Depth file saved successfully: {output_file}")
    print(f"Output shape: {df[available_cols].shape}")

    # Display summary statistics
    print("\nüìà Summary Statistics:")
    print(f"Date range: {df[date_col].min()} to {df[date_col].max()}")
    print(f"Temperature range: {df[temperature_col].min():.2f}¬∞C to {df[temperature_col].max():.2f}¬∞C")
    print(f"Precipitation range: {df[precipitation_col].min():.2f} mm to {df[precipitation_col].max():.2f} mm")
    print(f"Snow Depth range: {df['SnowDepth'].min():.2f} cm to {df['SnowDepth'].max():.2f} cm")

    print("\nFirst 10 rows of output:")
    print(df[available_cols].head(10))

    # Show some rows where snow accumulated
    snow_events = df[df['SnowDepth'] > 0]
    if not snow_events.empty:
        print(f"\n‚ùÑÔ∏è Snow events found ({len(snow_events)} rows with snow accumulation):")
        print(snow_events[available_cols].head(10))